"""
ML Classifier - –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI Embeddings –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ cosine similarity –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.
Fallback –Ω–∞ keyword matching –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
"""

import asyncio
import logging
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import aiohttp
import os

from sqlalchemy import select
from ...db import async_sessionmaker, Category

logger = logging.getLogger(__name__)

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")


class MLClassifier:
    """ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""

    def __init__(self):
        self.categories_cache = {}
        self.embeddings_cache = {}
        self.initialized = False
        self.fallback_keywords = {
            "–°–µ–º–µ–π–Ω–æ–µ –ø—Ä–∞–≤–æ": ["—Ä–∞–∑–≤–æ–¥", "–∞–ª–∏–º–µ–Ω—Ç", "–±—Ä–∞–∫", "—Å–µ–º—å", "–¥–µ—Ç–∏", "–æ–ø–µ–∫–∞"],
            "–ù–∞—Å–ª–µ–¥—Å—Ç–≤–æ": ["–Ω–∞—Å–ª–µ–¥—Å—Ç–≤", "–∑–∞–≤–µ—â–∞–Ω", "–Ω–∞—Å–ª–µ–¥–Ω–∏–∫", "–∏–º—É—â–µ—Å—Ç–≤–æ"],
            "–¢—Ä—É–¥–æ–≤—ã–µ —Å–ø–æ—Ä—ã": ["—Ä–∞–±–æ—Ç", "—Ç—Ä—É–¥", "—É–≤–æ–ª—å–Ω–µ–Ω", "–∑–∞—Ä–ø–ª–∞—Ç", "–æ—Ç–ø—É—Å–∫"],
            "–ñ–∏–ª–∏—â–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã": ["–∂–∫—Ö", "–∫–≤–∞—Ä—Ç–∏—Ä", "–¥–æ–º", "–∂–∏–ª—å", "–∫–æ–º–º—É–Ω–∞–ª—å–Ω"],
            "–ë–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤–æ —Ñ–∏–∑–ª–∏—Ü": ["–¥–æ–ª–≥", "–∫—Ä–µ–¥–∏—Ç", "–±–∞–Ω–∫—Ä–æ—Ç", "–¥–æ–ª–≥"],
            "–ù–∞–ª–æ–≥–æ–≤—ã–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏": ["–Ω–∞–ª–æ–≥", "–Ω–¥—Ñ–ª", "–∏—Ñ–Ω—Å", "–¥–µ–∫–ª–∞—Ä–∞—Ü"],
            "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —à—Ç—Ä–∞—Ñ—ã": ["—à—Ç—Ä–∞—Ñ", "–≥–∏–±–¥–¥", "–∞–¥–º–∏–Ω", "–Ω–∞—Ä—É—à–µ–Ω–∏"],
            "–ó–∞—â–∏—Ç–∞ –ø—Ä–∞–≤ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π": ["–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª", "—Ç–æ–≤–∞—Ä", "—É—Å–ª—É–≥", "–≤–æ–∑–≤—Ä–∞—Ç"],
            "–ú–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ –ø—Ä–∞–≤–æ": ["–º–∏–≥—Ä–∞", "–≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤", "–≤–Ω–∂", "—Ä–≤–ø", "–≤–∏–∑–∞"]
        }

    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
        try:
            logger.info("üîß Initializing ML Classifier...")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –ë–î
            await self._load_categories()

            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            if OPENROUTER_API_KEY:
                await self._initialize_category_embeddings()
            else:
                logger.warning(
                    "No OpenRouter API key - using keyword fallback only")

            self.initialized = True
            logger.info("‚úÖ ML Classifier initialized")

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize ML Classifier: {e}")
            self.initialized = False

    async def classify_message(self, message: str) -> Dict[str, Any]:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è

        Returns:
            {
                'category': str,
                'confidence': float,
                'all_predictions': Dict[str, float]
            }
        """
        try:
            if not self.initialized:
                await self.initialize()

            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º ML –ø–æ–¥—Ö–æ–¥
            if OPENROUTER_API_KEY and self.embeddings_cache:
                ml_result = await self._ml_classify(message)
                if ml_result['confidence'] > 0.6:  # –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    return ml_result

            # Fallback –Ω–∞ keyword matching
            keyword_result = await self._keyword_classify(message)

            return keyword_result

        except Exception as e:
            logger.error(f"Classification error: {e}")
            return {
                'category': "–û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã",
                'confidence': 0.3,
                'all_predictions': {}
            }

    async def _ml_classify(self, message: str) -> Dict[str, Any]:
        """ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è
            message_embedding = await self._get_embedding(message)
            if message_embedding is None:
                raise Exception("Failed to get message embedding")

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            similarities = {}
            for category, category_embedding in self.embeddings_cache.items():
                similarity = self._cosine_similarity(
                    message_embedding, category_embedding)
                similarities[category] = float(similarity)

            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            best_category = max(similarities, key=similarities.get)
            best_confidence = similarities[best_category]

            return {
                'category': best_category,
                'confidence': best_confidence,
                'all_predictions': similarities
            }

        except Exception as e:
            logger.error(f"ML classification error: {e}")
            return await self._keyword_classify(message)

    async def _keyword_classify(self, message: str) -> Dict[str, Any]:
        """Fallback –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        message_lower = message.lower()
        scores = {}

        for category, keywords in self.fallback_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in message_lower:
                    score += 1

            if score > 0:
                scores[category] = score / len(keywords)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º

        if scores:
            best_category = max(scores, key=scores.get)
            # –º–∞–∫—Å–∏–º—É–º 0.8 –¥–ª—è keyword
            confidence = min(scores[best_category] * 2, 0.8)

            return {
                'category': best_category,
                'confidence': confidence,
                'all_predictions': scores
            }

        return {
            'category': "–û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã",
            'confidence': 0.3,
            'all_predictions': {}
        }

    async def _load_categories(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –ë–î"""
        try:
            async with async_sessionmaker() as session:
                result = await session.execute(select(Category))
                categories = result.scalars().all()

                self.categories_cache = {
                    cat.name: cat.id for cat in categories}
                logger.info(f"Loaded {len(self.categories_cache)} categories")

        except Exception as e:
            logger.error(f"Failed to load categories: {e}")

    async def _initialize_category_embeddings(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        try:
            for category in self.categories_cache.keys():
                # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_text = f"–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–º–µ: {category}"
                embedding = await self._get_embedding(category_text)

                if embedding is not None:
                    self.embeddings_cache[category] = embedding

            logger.info(
                f"Created embeddings for {len(self.embeddings_cache)} categories")

        except Exception as e:
            logger.error(f"Failed to create category embeddings: {e}")

    async def _get_embedding(self, text: str) -> Optional[np.ndarray]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ OpenAI"""
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "Content-Type": "application/json",
                }

                data = {
                    "model": "openai/text-embedding-3-small",
                    "input": text
                }

                async with session.post(
                    "https://openrouter.ai/api/v1/embeddings",
                    headers=headers,
                    json=data
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        embedding = result["data"][0]["embedding"]
                        return np.array(embedding)
                    else:
                        logger.error(f"Embedding API error: {response.status}")
                        return None

        except Exception as e:
            logger.error(f"Failed to get embedding: {e}")
            return None

    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ cosine similarity"""
        try:
            dot_product = np.dot(a, b)
            norm_a = np.linalg.norm(a)
            norm_b = np.linalg.norm(b)

            if norm_a == 0 or norm_b == 0:
                return 0.0

            return dot_product / (norm_a * norm_b)

        except Exception as e:
            logger.error(f"Cosine similarity error: {e}")
            return 0.0

    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
        return {
            "status": "ok" if self.initialized else "not_initialized",
            "categories_loaded": len(self.categories_cache),
            "embeddings_ready": len(self.embeddings_cache),
            "ml_available": bool(OPENROUTER_API_KEY)
        }
