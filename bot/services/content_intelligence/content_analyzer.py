"""
üîç CONTENT ANALYZER
NLP –∞–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

import re
from typing import Dict
from .models import NewsItem

class ContentAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å NLP"""
    
    def __init__(self):
        self.legal_keywords = {
            'high_relevance': [
                '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω', '–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ', '–ø—Ä–∏–∫–∞–∑', '—Ä–µ—à–µ–Ω–∏–µ —Å—É–¥–∞',
                '–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω—ã–π —Å—É–¥', '–≤–µ—Ä—Ö–æ–≤–Ω—ã–π —Å—É–¥', '–∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–π —Å—É–¥',
                '–Ω–∞–ª–æ–≥–æ–≤—ã–π –∫–æ–¥–µ–∫—Å', '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å', '—Ç—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å'
            ],
            'medium_relevance': [
                '–ø—Ä–∞–≤–∞ –≥—Ä–∞–∂–¥–∞–Ω', '—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —É—Å–ª—É–≥–∏', '–ø—Ä–∞–≤–æ–≤–∞—è –ø–æ–º–æ—â—å',
                '—Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞', '–∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ',
                '–Ω–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞', '—à—Ç—Ä–∞—Ñ—ã', '–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏'
            ],
            'legal_entities': [
                '–º–∏–Ω—é—Å—Ç', '—Ä–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä', '—Ñ–∞—Å', '—Ñ–Ω—Å', '—Ü–± —Ä—Ñ',
                '—Ä–æ—Å—Ä–µ–µ—Å—Ç—Ä', '–ø—Ñ—Ä', '—Ñ—Å—Å', '—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä'
            ]
        }
    
    async def analyze_relevance(self, news_item: NewsItem) -> float:
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        text = f"{news_item.title} {news_item.content}".lower()
        score = 0.0
        
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for keyword in self.legal_keywords['high_relevance']:
            if keyword in text:
                score += 0.3
        
        for keyword in self.legal_keywords['medium_relevance']:
            if keyword in text:
                score += 0.2
        
        for keyword in self.legal_keywords['legal_entities']:
            if keyword in text:
                score += 0.1
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        if news_item.source in ['pravo_gov', 'ksrf']:
            score += 0.4  # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤–∞–∂–Ω–µ–µ
        
        if any(word in text for word in ['–Ω–æ–≤—ã–π', '–∏–∑–º–µ–Ω–µ–Ω–∏—è', '–≤—Å—Ç—É–ø–∏–ª –≤ —Å–∏–ª—É']):
            score += 0.2  # –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-1
        return min(score, 1.0)
    
    async def analyze_content_quality(self, news_item: NewsItem) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        
        content_len = len(news_item.content)
        
        quality_metrics = {
            'title_quality': self._score_title_quality(news_item.title),
            'content_length': min(content_len / 500, 1.0),
            'informativeness': self._score_informativeness(news_item.content),
            'readability': self._score_readability(news_item.content)
        }
        
        return quality_metrics
    
    def _score_title_quality(self, title: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        score = 0.5
        
        # –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        if 30 <= len(title) <= 100:
            score += 0.2
        
        # –ù–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if any(word in title.lower() for word in ['–∑–∞–∫–æ–Ω', '–ø—Ä–∞–≤–∞', '—Å—É–¥', '–Ω–æ–≤—ã–µ']):
            score += 0.2
        
        # –ò–∑–±–µ–≥–∞–µ–º clickbait
        if not any(word in title.lower() for word in ['—à–æ–∫', '—Å–µ–Ω—Å–∞—Ü–∏—è', '!!!']):
            score += 0.1
        
        return min(score, 1.0)
    
    def _score_informativeness(self, content: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        score = 0.3
        
        # –ù–∞–ª–∏—á–∏–µ –¥–∞—Ç
        if re.search(r'\d{1,2}\.\d{1,2}\.\d{4}', content):
            score += 0.2
        
        # –ù–∞–ª–∏—á–∏–µ —Ü–∏—Ñ—Ä
        if re.search(r'\d+', content):
            score += 0.1
        
        # –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∑–∞–∫–æ–Ω–∞
        if re.search(r'—Å—Ç–∞—Ç—å[—è–∏–µ] \d+', content.lower()):
            score += 0.2
        
        # –°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        if any(word in content.lower() for word in ['‚Ññ', '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω']):
            score += 0.2
        
        return min(score, 1.0)
    
    def _score_readability(self, content: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"""
        sentences = content.split('.')
        if not sentences:
            return 0.3
        
        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences)
        
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è 10-20 —Å–ª–æ–≤
        if 10 <= avg_sentence_length <= 20:
            return 0.8
        elif 5 <= avg_sentence_length <= 30:
            return 0.6
        else:
            return 0.4
