"""AI helper using Azure OpenAI ONLY.
Functions: chat_complete, humanize, generate_content.
–¢–û–õ–¨–ö–û AZURE OPENAI - OpenRouter –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–±—Ä–∞–Ω!
"""

import os
import aiohttp
import json

# Azure OpenAI Configuration - –¢–û–õ–¨–ö–û AZURE!
AZURE_OPENAI_API_KEY = os.getenv(
    "AZURE_OPENAI_API_KEY", "Fjaj2B7pc9tXPnLT4jY8Wv4Gl9435Ifw6ymyQ68OolKP0LVxBoqjJQQJ99BEACfhMk5XJ3w3AAAAACOGrsqR")
AZURE_OPENAI_ENDPOINT = os.getenv(
    "AZURE_OPENAI_ENDPOINT", "https://divan-mb68c0s7-swedencentral.cognitiveservices.azure.com")
AZURE_OPENAI_API_VERSION = os.getenv(
    "AZURE_OPENAI_API_VERSION", "2024-02-15-preview")


async def generate_ai_response(messages: list[dict], model: str = "gpt-4o-mini", max_tokens: int = 800) -> str:
    """Generate AI response using –¢–û–õ–¨–ö–û Azure OpenAI"""

    # –¢–û–õ–¨–ö–û Azure OpenAI - –±–µ–∑ fallback –Ω–∞ OpenRouter!
    if AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT:
        try:
            return await _azure_openai_request(messages, model, max_tokens)
        except Exception as e:
            print(f"‚ùå Azure OpenAI error: {e}")
            return "ü§ñ AI –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Azure OpenAI."

    return "ü§ñ Azure OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."


async def _azure_openai_request(messages: list[dict], model: str, max_tokens: int) -> str:
    """Make request to Azure OpenAI - –û–ë–ù–û–í–õ–ï–ù–ù–´–ô MAPPING"""
    async with aiohttp.ClientSession() as session:
        headers = {
            "api-key": AZURE_OPENAI_API_KEY,
            "Content-Type": "application/json",
        }

        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô Azure OpenAI deployment mapping –¥–ª—è –≤–∞—à–∏—Ö actual deployments
        deployment_map = {
            "gpt-4o-mini": "gpt-35-turbo",          # –∏—Å–ø–æ–ª—å–∑—É–µ–º gpt-35-turbo
            "gpt-4o": "gpt-4.1",                   # –∏—Å–ø–æ–ª—å–∑—É–µ–º gpt-4.1
            "gpt-35-turbo": "gpt-35-turbo",        # –ø—Ä—è–º–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            "gpt-4.1": "gpt-4.1",                  # –ø—Ä—è–º–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            "openai/gpt-4o-mini": "gpt-35-turbo",  # fallback
            "openai/gpt-4o": "gpt-4.1"             # fallback
        }

        deployment_name = deployment_map.get(
            model, "gpt-35-turbo")  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gpt-35-turbo

        print(
            f"üîß Using Azure deployment: {deployment_name} for model: {model}")

        url = f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{deployment_name}/chat/completions?api-version={AZURE_OPENAI_API_VERSION}"

        data = {
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": 0.7
        }

        async with session.post(url, headers=headers, json=data) as response:
            if response.status == 200:
                result = await response.json()
                print(f"‚úÖ Azure OpenAI SUCCESS with {deployment_name}")
                return result["choices"][0]["message"]["content"].strip()
            else:
                error_text = await response.text()
                print(
                    f"‚ùå Azure OpenAI deployment {deployment_name} error {response.status}: {error_text}")
                raise Exception(
                    f"Azure OpenAI failed with status {response.status}")


async def generate_post_content(topic: str) -> str:
    """Generate post content for channel using Azure OpenAI"""
    messages = [
        {"role": "system", "content": "–¢—ã —é—Ä–∏—Å—Ç, –ø–∏—à–µ—à—å –ø–æ–ª–µ–∑–Ω—ã–µ –ø–æ—Å—Ç—ã –¥–ª—è Telegram –∫–∞–Ω–∞–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏."},
        {"role": "user", "content": f"–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –Ω–∞ —Ç–µ–º—É: {topic}. –û–±—ä–µ–º 300-400 —Å–∏–º–≤–æ–ª–æ–≤."}
    ]
    return await generate_ai_response(messages)
