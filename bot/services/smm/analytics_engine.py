"""
üìä ANALYTICS ENGINE
Advanced analytics and metrics tracking for SMM campaigns
"""

import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json

logger = logging.getLogger(__name__)


class MetricType(Enum):
    """–¢–∏–ø—ã –º–µ—Ç—Ä–∏–∫"""
    ENGAGEMENT_RATE = "engagement_rate"
    CONVERSION_RATE = "conversion_rate"
    VIRAL_COEFFICIENT = "viral_coefficient"
    RETENTION_RATE = "retention_rate"
    CLV = "customer_lifetime_value"
    REACH = "reach"
    IMPRESSIONS = "impressions"
    CLICK_THROUGH_RATE = "click_through_rate"
    COST_PER_ACQUISITION = "cost_per_acquisition"
    BRAND_MENTION_SENTIMENT = "brand_mention_sentiment"


class ContentPerformanceCategory(Enum):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    VIRAL_HIT = "viral_hit"           # >1000 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    HIGH_PERFORMER = "high_performer"  # 500-1000 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    AVERAGE = "average"               # 100-500 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    LOW_PERFORMER = "low_performer"   # 50-100 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    FLOP = "flop"                    # <50 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π


@dataclass
class ContentMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    content_id: str
    content_type: str
    publish_time: datetime
    views: int = 0
    likes: int = 0
    comments: int = 0
    shares: int = 0
    saves: int = 0
    click_throughs: int = 0
    conversions: int = 0
    engagement_rate: float = 0.0
    viral_coefficient: float = 0.0
    conversion_rate: float = 0.0
    performance_category: Optional[ContentPerformanceCategory] = None
    ab_test_variant: Optional[str] = None
    audience_segments: List[str] = field(default_factory=list)
    revenue_attributed: float = 0.0


@dataclass
class AudienceInsights:
    """–ò–Ω—Å–∞–π—Ç—ã –æ–± –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
    total_reach: int
    active_users: int
    new_users: int
    returning_users: int
    demographics: Dict[str, Any]
    interests: List[str]
    peak_activity_hours: List[int]
    preferred_content_types: List[str]
    engagement_patterns: Dict[str, float]
    churn_risk_segments: List[str]


@dataclass
class CampaignPerformance:
    """–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–∞–º–ø–∞–Ω–∏–∏"""
    campaign_id: str
    start_date: datetime
    end_date: datetime
    total_reach: int
    total_impressions: int
    total_engagement: int
    total_conversions: int
    total_revenue: float
    cost_per_acquisition: float
    return_on_ad_spend: float
    viral_amplification: float
    brand_lift: float


@dataclass
class CompetitorBenchmark:
    """–ë–µ–Ω—á–º–∞—Ä–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
    competitor_name: str
    their_engagement_rate: float
    their_posting_frequency: int
    their_top_content_types: List[str]
    their_audience_overlap: float
    performance_gap: float
    opportunities: List[str]


class AnalyticsEngine:
    """–î–≤–∏–∂–æ–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""

    def __init__(self):
        self.metrics_storage = MetricsStorage()
        self.performance_analyzer = PerformanceAnalyzer()
        self.audience_analyzer = AudienceAnalyzer()
        self.competitive_analyzer = CompetitiveAnalyzer()
        self.prediction_engine = PredictionEngine()

    async def track_content_performance(
        self,
        content_id: str,
        metrics_update: Dict[str, Any]
    ) -> ContentMetrics:
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ
            metrics = await self.metrics_storage.get_content_metrics(content_id)
            if not metrics:
                metrics = ContentMetrics(
                    content_id=content_id,
                    content_type=metrics_update.get('content_type', 'unknown'),
                    publish_time=metrics_update.get(
                        'publish_time', datetime.now())
                )

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            await self._update_content_metrics(metrics, metrics_update)

            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            await self._calculate_derived_metrics(metrics)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            metrics.performance_category = await self._categorize_performance(metrics)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            await self.metrics_storage.save_content_metrics(metrics)

            logger.info(
                f"Updated metrics for content {content_id}: {metrics.performance_category}")
            return metrics

        except Exception as e:
            logger.error(
                f"Failed to track content performance for {content_id}: {e}")
            raise

    async def generate_comprehensive_report(
        self,
        period_start: datetime,
        period_end: datetime,
        include_predictions: bool = True
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""

        try:
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            content_analytics = await self._analyze_content_performance(period_start, period_end)
            audience_analytics = await self._analyze_audience_behavior(period_start, period_end)
            competitive_analytics = await self._analyze_competitive_landscape()

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã
            insights = await self._generate_actionable_insights(
                content_analytics, audience_analytics, competitive_analytics
            )

            # –ü—Ä–æ–≥–Ω–æ–∑—ã
            predictions = {}
            if include_predictions:
                predictions = await self.prediction_engine.generate_predictions(
                    content_analytics, audience_analytics
                )

            report = {
                'period': {
                    'start': period_start.isoformat(),
                    'end': period_end.isoformat()
                },
                'executive_summary': await self._generate_executive_summary(
                    content_analytics, audience_analytics
                ),
                'content_performance': content_analytics,
                'audience_insights': audience_analytics,
                'competitive_analysis': competitive_analytics,
                'actionable_insights': insights,
                'predictions': predictions,
                'recommendations': await self._generate_recommendations(insights),
                'generated_at': datetime.now().isoformat()
            }

            logger.info(
                f"Generated comprehensive report for {period_start} - {period_end}")
            return report

        except Exception as e:
            logger.error(f"Failed to generate comprehensive report: {e}")
            raise

    async def _analyze_content_performance(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
        all_metrics = await self.metrics_storage.get_metrics_by_period(start_date, end_date)

        if not all_metrics:
            return {'error': 'No data available for the period'}

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        by_content_type = {}
        for metrics in all_metrics:
            content_type = metrics.content_type
            if content_type not in by_content_type:
                by_content_type[content_type] = []
            by_content_type[content_type].append(metrics)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø
        content_analysis = {}
        for content_type, metrics_list in by_content_type.items():
            content_analysis[content_type] = await self._analyze_content_type_performance(
                metrics_list
            )

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_metrics = await self._calculate_total_metrics(all_metrics)

        # –¢–æ–ø –∫–æ–Ω—Ç–µ–Ω—Ç
        top_performers = await self._identify_top_performers(all_metrics)

        # A/B —Ç–µ—Å—Ç—ã
        ab_test_results = await self._analyze_ab_tests(all_metrics)

        return {
            'total_metrics': total_metrics,
            'by_content_type': content_analysis,
            'top_performers': top_performers,
            'bottom_performers': await self._identify_bottom_performers(all_metrics),
            'ab_test_results': ab_test_results,
            'trends': await self._identify_performance_trends(all_metrics),
            'optimization_opportunities': await self._identify_optimization_opportunities(all_metrics)
        }

    async def _analyze_audience_behavior(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> AudienceInsights:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –∞—É–¥–∏—Ç–æ—Ä–∏–∏
        audience_data = await self.audience_analyzer.get_audience_data(start_date, end_date)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—é
        demographics = await self.audience_analyzer.analyze_demographics(audience_data)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ—Ä–µ—Å—ã
        interests = await self.audience_analyzer.extract_interests(audience_data)

        # –ù–∞—Ö–æ–¥–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        activity_patterns = await self.audience_analyzer.analyze_activity_patterns(audience_data)

        # –°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –∞—É–¥–∏—Ç–æ—Ä–∏—é
        segments = await self.audience_analyzer.segment_audience(audience_data)

        return AudienceInsights(
            total_reach=audience_data.get('total_reach', 0),
            active_users=audience_data.get('active_users', 0),
            new_users=audience_data.get('new_users', 0),
            returning_users=audience_data.get('returning_users', 0),
            demographics=demographics,
            interests=interests,
            peak_activity_hours=activity_patterns.get('peak_hours', []),
            preferred_content_types=activity_patterns.get(
                'preferred_content', []),
            engagement_patterns=activity_patterns.get(
                'engagement_patterns', {}),
            churn_risk_segments=segments.get('churn_risk', [])
        )

    async def _analyze_competitive_landscape(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π —Å—Ä–µ–¥—ã"""

        competitors = await self.competitive_analyzer.get_competitors_list()

        benchmarks = []
        for competitor in competitors:
            benchmark = await self.competitive_analyzer.analyze_competitor(competitor)
            benchmarks.append(benchmark)

        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        market_insights = await self.competitive_analyzer.generate_market_insights(benchmarks)

        return {
            'competitors_analyzed': len(competitors),
            'benchmarks': [benchmark.__dict__ for benchmark in benchmarks],
            'market_insights': market_insights,
            'our_position': await self.competitive_analyzer.assess_our_position(benchmarks),
            'opportunities': await self.competitive_analyzer.identify_opportunities(benchmarks)
        }

    async def _generate_actionable_insights(
        self,
        content_analytics: Dict[str, Any],
        audience_analytics: AudienceInsights,
        competitive_analytics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è actionable –∏–Ω—Å–∞–π—Ç–æ–≤"""

        insights = []

        # –ò–Ω—Å–∞–π—Ç—ã –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É
        if content_analytics.get('top_performers'):
            top_content_types = [p['content_type']
                                 for p in content_analytics['top_performers'][:3]]
            insights.append({
                'category': 'content_optimization',
                'insight': f"–¢–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –ª—É—á—à–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é: {', '.join(top_content_types)}",
                'action': f"–£–≤–µ–ª–∏—á–∏—Ç—å –¥–æ–ª—é —ç—Ç–∏—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ 30%",
                'expected_impact': '–†–æ—Å—Ç engagement –Ω–∞ 25-40%',
                'priority': 'high'
            })

        # –ò–Ω—Å–∞–π—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        peak_hours = audience_analytics.peak_activity_hours
        if peak_hours:
            insights.append({
                'category': 'timing_optimization',
                'insight': f"–ü–∏–∫ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏: {peak_hours[0]:02d}:00-{peak_hours[-1]:02d}:00",
                'action': f"–ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ 70% –ø—É–±–ª–∏–∫–∞—Ü–∏–π –Ω–∞ –≤—Ä–µ–º—è {peak_hours[0]}-{peak_hours[-1]} —á–∞—Å–æ–≤",
                'expected_impact': '–†–æ—Å—Ç –æ—Ö–≤–∞—Ç–∞ –Ω–∞ 15-25%',
                'priority': 'medium'
            })

        # –ò–Ω—Å–∞–π—Ç—ã –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º –∞—É–¥–∏—Ç–æ—Ä–∏–∏
        if audience_analytics.churn_risk_segments:
            insights.append({
                'category': 'retention_optimization',
                'insight': f"–°–µ–≥–º–µ–Ω—Ç—ã —Å —Ä–∏—Å–∫–æ–º –æ—Ç—Ç–æ–∫–∞: {len(audience_analytics.churn_risk_segments)}",
                'action': "–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é retention-–∫–∞–º–ø–∞–Ω–∏—é",
                'expected_impact': '–°–Ω–∏–∂–µ–Ω–∏–µ churn –Ω–∞ 30%',
                'priority': 'high'
            })

        # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã
        if competitive_analytics.get('opportunities'):
            for opportunity in competitive_analytics['opportunities'][:2]:
                insights.append({
                    'category': 'competitive_advantage',
                    'insight': f"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å: {opportunity}",
                    'action': "–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏",
                    'expected_impact': '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∑–∞—Ö–≤–∞—Ç 10-15% –¥–æ–ª–∏ —Ä—ã–Ω–∫–∞',
                    'priority': 'medium'
                })

        return insights

    async def _generate_recommendations(
        self,
        insights: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Å–∞–π—Ç–æ–≤"""

        recommendations = []

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        high_priority = [i for i in insights if i['priority'] == 'high']
        medium_priority = [i for i in insights if i['priority'] == 'medium']

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤
        for insight in high_priority:
            if insight['category'] == 'content_optimization':
                recommendations.append({
                    'title': '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç-—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏',
                    'description': insight['action'],
                    'implementation_steps': [
                        '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞',
                        '–£–≤–µ–ª–∏—á–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Ç–æ–ø-—Ç–∏–ø–æ–≤',
                        '–°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü',
                        '–û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö'
                    ],
                    'timeline': '2 –Ω–µ–¥–µ–ª–∏',
                    'resources_needed': ['–ö–æ–Ω—Ç–µ–Ω—Ç-–º–µ–Ω–µ–¥–∂–µ—Ä', '–î–∏–∑–∞–π–Ω–µ—Ä'],
                    'expected_roi': '200-300%'
                })

            elif insight['category'] == 'retention_optimization':
                recommendations.append({
                    'title': '–ü—Ä–æ–≥—Ä–∞–º–º–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏',
                    'description': insight['action'],
                    'implementation_steps': [
                        '–°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏—Ç–æ—Ä–∏—é –ø–æ —Ä–∏—Å–∫—É –æ—Ç—Ç–æ–∫–∞',
                        '–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏',
                        '–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã',
                        '–ó–∞–ø—É—Å—Ç–∏—Ç—å A/B —Ç–µ—Å—Ç –∫–∞–º–ø–∞–Ω–∏–∏'
                    ],
                    'timeline': '3 –Ω–µ–¥–µ–ª–∏',
                    'resources_needed': ['–ú–∞—Ä–∫–µ—Ç–æ–ª–æ–≥', '–ê–Ω–∞–ª–∏—Ç–∏–∫', '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫'],
                    'expected_roi': '150-250%'
                })

        # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations.append({
            'title': '–†–∞–∑–≤–∏—Ç–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π',
            'description': '–í–Ω–µ–¥—Ä–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è',
            'implementation_steps': [
                '–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö',
                '–í–Ω–µ–¥—Ä–∏—Ç—å predictive analytics',
                '–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–Ω—Å–∞–π—Ç–æ–≤',
                '–°–æ–∑–¥–∞—Ç—å real-time –¥–∞—à–±–æ—Ä–¥—ã'
            ],
            'timeline': '2 –º–µ—Å—è—Ü–∞',
            'resources_needed': ['Data Scientist', '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '–ê–Ω–∞–ª–∏—Ç–∏–∫'],
            'expected_roi': '300-500%'
        })

        return recommendations

    async def _update_content_metrics(
        self,
        metrics: ContentMetrics,
        update: Dict[str, Any]
    ):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        for field, value in update.items():
            if hasattr(metrics, field):
                setattr(metrics, field, value)

    async def _calculate_derived_metrics(self, metrics: ContentMetrics):
        """–†–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""

        # Engagement rate
        total_interactions = metrics.likes + \
            metrics.comments + metrics.shares + metrics.saves
        if metrics.views > 0:
            metrics.engagement_rate = total_interactions / metrics.views

        # Viral coefficient
        if metrics.views > 0:
            metrics.viral_coefficient = metrics.shares / metrics.views

        # Conversion rate
        if metrics.click_throughs > 0:
            metrics.conversion_rate = metrics.conversions / metrics.click_throughs

    async def _categorize_performance(self, metrics: ContentMetrics) -> ContentPerformanceCategory:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        total_interactions = metrics.likes + \
            metrics.comments + metrics.shares + metrics.saves

        if total_interactions >= 1000:
            return ContentPerformanceCategory.VIRAL_HIT
        elif total_interactions >= 500:
            return ContentPerformanceCategory.HIGH_PERFORMER
        elif total_interactions >= 100:
            return ContentPerformanceCategory.AVERAGE
        elif total_interactions >= 50:
            return ContentPerformanceCategory.LOW_PERFORMER
        else:
            return ContentPerformanceCategory.FLOP


class MetricsStorage:
    """–•—Ä–∞–Ω–∏–ª–∏—â–µ –º–µ—Ç—Ä–∏–∫"""

    def __init__(self):
        self.metrics_cache: Dict[str, ContentMetrics] = {}

    async def get_content_metrics(self, content_id: str) -> Optional[ContentMetrics]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        return self.metrics_cache.get(content_id)

    async def save_content_metrics(self, metrics: ContentMetrics):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        self.metrics_cache[metrics.content_id] = metrics

    async def get_metrics_by_period(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[ContentMetrics]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        return [
            metrics for metrics in self.metrics_cache.values()
            if start_date <= metrics.publish_time <= end_date
        ]


class PerformanceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""

    async def analyze_trends(self, metrics_list: List[ContentMetrics]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤
        return {
            'engagement_trend': 'growing',
            'viral_trend': 'stable',
            'conversion_trend': 'growing'
        }


class AudienceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""

    async def get_audience_data(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
        # –ó–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –ë–î/API
        return {
            'total_reach': 50000,
            'active_users': 15000,
            'new_users': 5000,
            'returning_users': 10000
        }

    async def analyze_demographics(self, audience_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏–∏"""
        return {
            'age_groups': {'25-34': 40, '35-44': 30, '18-24': 20, '45+': 10},
            'gender': {'male': 60, 'female': 40},
            'locations': {'moscow': 35, 'spb': 15, 'other': 50}
        }

    async def extract_interests(self, audience_data: Dict[str, Any]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
        return ['–ø—Ä–∞–≤–æ', '–±–∏–∑–Ω–µ—Å', '—Ñ–∏–Ω–∞–Ω—Å—ã', '–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏']

    async def analyze_activity_patterns(self, audience_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        return {
            'peak_hours': [9, 10, 11, 18, 19, 20],
            'preferred_content': ['viral_case_study', 'legal_life_hack', 'trending_legal_news'],
            'engagement_patterns': {
                'morning': 0.8,
                'afternoon': 0.6,
                'evening': 0.9,
                'night': 0.3
            }
        }

    async def segment_audience(self, audience_data: Dict[str, Any]) -> Dict[str, List[str]]:
        """–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
        return {
            'churn_risk': ['inactive_users', 'low_engagement'],
            'high_value': ['active_commenters', 'frequent_converters'],
            'growth_potential': ['new_users', 'medium_engagement']
        }


class CompetitiveAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π —Å—Ä–µ–¥—ã"""

    async def get_competitors_list(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
        return ['–Æ—Ä–∏—Å—Ç24', '–ü—Ä–∞–≤–æ–≤–µ–¥–™', '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –ø–æ–º–æ—â—å –æ–Ω–ª–∞–π–Ω']

    async def analyze_competitor(self, competitor: str) -> CompetitorBenchmark:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        # –ó–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Å–∏–Ω–≥ –∏—Ö –∫–∞–Ω–∞–ª–æ–≤
        return CompetitorBenchmark(
            competitor_name=competitor,
            their_engagement_rate=0.05,
            their_posting_frequency=3,
            their_top_content_types=['legal_news', 'q_and_a'],
            their_audience_overlap=0.2,
            performance_gap=-0.02,
            opportunities=['video_content', 'interactive_posts']
        )

    async def generate_market_insights(
        self,
        benchmarks: List[CompetitorBenchmark]
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤"""
        return {
            'market_avg_engagement': 0.04,
            'our_position': 'above_average',
            'growth_opportunities': ['video', 'stories', 'live_sessions'],
            'content_gaps': ['tax_law', 'corporate_law']
        }

    async def assess_our_position(
        self,
        benchmarks: List[CompetitorBenchmark]
    ) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –Ω–∞—à–µ–π –ø–æ–∑–∏—Ü–∏–∏"""
        return {
            'engagement_rank': 2,
            'content_quality_rank': 1,
            'audience_growth_rank': 3,
            'overall_rank': 2
        }

    async def identify_opportunities(
        self,
        benchmarks: List[CompetitorBenchmark]
    ) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        opportunities = []
        for benchmark in benchmarks:
            opportunities.extend(benchmark.opportunities)

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        unique_opportunities = list(set(opportunities))
        return unique_opportunities[:5]


class PredictionEngine:
    """–î–≤–∏–∂–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""

    async def generate_predictions(
        self,
        content_analytics: Dict[str, Any],
        audience_analytics: AudienceInsights
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""

        return {
            'next_month_growth': {
                'audience_growth': '+15%',
                'engagement_growth': '+12%',
                'conversion_growth': '+8%'
            },
            'optimal_content_mix': {
                'viral_case_study': '30%',
                'legal_life_hack': '25%',
                'trending_legal_news': '20%',
                'interactive_quiz': '15%',
                'other': '10%'
            },
            'revenue_forecast': {
                'next_month': '+25%',
                'next_quarter': '+45%',
                'confidence': '85%'
            },
            'risk_factors': [
                'Seasonal drop in legal queries',
                'New competitor entry',
                'Platform algorithm changes'
            ]
        }
