"""
üß™ A/B TESTING ENGINE - PRODUCTION READY
Advanced A/B testing system for SMM content optimization:
- Multiple variant testing (A/B/C/D...)
- Statistical significance calculation
- Automatic winner selection
- Content optimization insights
- Performance tracking
- Real-time results analysis
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import json
import math
import random
from statistics import mean, stdev

logger = logging.getLogger(__name__)


class TestStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã A/B —Ç–µ—Å—Ç–æ–≤"""
    DRAFT = "draft"
    RUNNING = "running"
    COMPLETED = "completed"
    PAUSED = "paused"
    CANCELLED = "cancelled"


class VariantType(Enum):
    """–¢–∏–ø—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    CONTENT = "content"        # –†–∞–∑–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    TITLE = "title"           # –†–∞–∑–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    TIMING = "timing"         # –†–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    FORMAT = "format"         # –†–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã (—Ç–µ–∫—Å—Ç/—Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ)
    CTA = "cta"              # –†–∞–∑–Ω—ã–µ –ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é
    HASHTAGS = "hashtags"     # –†–∞–∑–Ω—ã–µ —Ö–µ—à—Ç–µ–≥–∏
    LENGTH = "length"         # –†–∞–∑–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞


class MetricType(Enum):
    """–¢–∏–ø—ã –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    ENGAGEMENT_RATE = "engagement_rate"
    CLICK_RATE = "click_rate"
    CONVERSION_RATE = "conversion_rate"
    VIEWS = "views"
    COMMENTS = "comments"
    SHARES = "shares"
    TIME_SPENT = "time_spent"


@dataclass
class TestVariant:
    """–í–∞—Ä–∏–∞–Ω—Ç A/B —Ç–µ—Å—Ç–∞"""
    variant_id: str
    variant_name: str
    content: Dict[str, Any]
    weight: float = 1.0  # –í–µ—Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞

    # –ú–µ—Ç—Ä–∏–∫–∏
    impressions: int = 0
    views: int = 0
    engagements: int = 0
    clicks: int = 0
    conversions: int = 0

    # –†–∞—Å—á–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    engagement_rate: float = 0.0
    click_rate: float = 0.0
    conversion_rate: float = 0.0

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    confidence_level: float = 0.0
    statistical_significance: bool = False


@dataclass
class ABTest:
    """A/B —Ç–µ—Å—Ç"""
    test_id: str
    test_name: str
    test_type: VariantType
    primary_metric: MetricType
    secondary_metrics: List[MetricType]

    variants: List[TestVariant]

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ—Å—Ç–∞
    start_date: datetime
    end_date: Optional[datetime] = None
    min_sample_size: int = 100
    confidence_threshold: float = 0.95
    max_duration_days: int = 14

    # –°—Ç–∞—Ç—É—Å
    status: TestStatus = TestStatus.DRAFT
    winner_variant_id: Optional[str] = None

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    total_impressions: int = 0
    test_results: Dict[str, Any] = None

    def __post_init__(self):
        if self.test_results is None:
            self.test_results = {}


@dataclass
class TestResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç A/B —Ç–µ—Å—Ç–∞"""
    test_id: str
    winner_variant_id: str
    confidence_level: float
    improvement_percentage: float
    statistical_significance: bool
    recommendation: str
    detailed_metrics: Dict[str, Any]
    generated_at: datetime


class ABTestingEngine:
    """Production-ready A/B testing engine"""

    def __init__(self):
        self.active_tests: Dict[str, ABTest] = {}
        self.completed_tests: Dict[str, ABTest] = {}
        self.test_assignments: Dict[str, str] = {}  # user_id -> variant_id

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.min_confidence_level = 0.95
        self.min_sample_size = 50
        self.max_concurrent_tests = 5

        self.is_running = False

    async def start_engine(self):
        """–ó–∞–ø—É—Å–∫ –¥–≤–∏–∂–∫–∞ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.is_running = True
        logger.info("üß™ Starting A/B Testing Engine")

        # –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –≤ —Ñ–æ–Ω–µ (–Ω–µ –∂–¥–µ–º –∏—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è)
        asyncio.create_task(self._monitor_active_tests())
        asyncio.create_task(self._calculate_test_results())
        asyncio.create_task(self._auto_stop_completed_tests())

        logger.info("‚úÖ A/B Testing Engine background tasks started")

    async def stop_engine(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–≤–∏–∂–∫–∞"""
        self.is_running = False
        logger.info("üõë Stopping A/B Testing Engine")

    async def create_content_test(
        self,
        test_name: str,
        variants_content: List[Dict[str, Any]],
        primary_metric: MetricType = MetricType.ENGAGEMENT_RATE,
        duration_days: int = 7
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        test_id = f"content_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}"

        # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
        variants = []
        for i, content in enumerate(variants_content):
            variant = TestVariant(
                variant_id=f"{test_id}_variant_{chr(65+i)}",  # A, B, C...
                variant_name=f"Variant {chr(65+i)}",
                content=content
            )
            variants.append(variant)

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç
        ab_test = ABTest(
            test_id=test_id,
            test_name=test_name,
            test_type=VariantType.CONTENT,
            primary_metric=primary_metric,
            secondary_metrics=[MetricType.CLICK_RATE, MetricType.VIEWS],
            variants=variants,
            start_date=datetime.now(),
            end_date=datetime.now() + timedelta(days=duration_days),
            max_duration_days=duration_days
        )

        self.active_tests[test_id] = ab_test

        logger.info(
            f"üß™ Created A/B test {test_id} with {len(variants)} variants")

        return test_id

    async def create_timing_test(
        self,
        test_name: str,
        post_content: Dict[str, Any],
        time_variants: List[int],  # –ß–∞—Å—ã –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        duration_days: int = 14
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""

        test_id = f"timing_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}"

        variants = []
        for i, hour in enumerate(time_variants):
            variant_content = post_content.copy()
            variant_content['publish_hour'] = hour

            variant = TestVariant(
                variant_id=f"{test_id}_time_{hour}h",
                variant_name=f"–í—Ä–µ–º—è {hour}:00",
                content=variant_content
            )
            variants.append(variant)

        ab_test = ABTest(
            test_id=test_id,
            test_name=test_name,
            test_type=VariantType.TIMING,
            primary_metric=MetricType.ENGAGEMENT_RATE,
            secondary_metrics=[MetricType.VIEWS, MetricType.CLICK_RATE],
            variants=variants,
            start_date=datetime.now(),
            end_date=datetime.now() + timedelta(days=duration_days),
            max_duration_days=duration_days
        )

        self.active_tests[test_id] = ab_test

        logger.info(
            f"‚è∞ Created timing A/B test {test_id} for hours: {time_variants}")

        return test_id

    async def create_format_test(
        self,
        test_name: str,
        base_content: str,
        formats: List[str],  # ["text", "photo", "video", "poll"]
        duration_days: int = 7
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        test_id = f"format_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}"

        variants = []
        for format_type in formats:
            variant_content = {
                "text": base_content,
                "format": format_type,
                "media_required": format_type != "text"
            }

            variant = TestVariant(
                variant_id=f"{test_id}_format_{format_type}",
                variant_name=f"–§–æ—Ä–º–∞—Ç: {format_type}",
                content=variant_content
            )
            variants.append(variant)

        ab_test = ABTest(
            test_id=test_id,
            test_name=test_name,
            test_type=VariantType.FORMAT,
            primary_metric=MetricType.ENGAGEMENT_RATE,
            secondary_metrics=[MetricType.VIEWS, MetricType.CLICK_RATE],
            variants=variants,
            start_date=datetime.now(),
            end_date=datetime.now() + timedelta(days=duration_days),
            max_duration_days=duration_days
        )

        self.active_tests[test_id] = ab_test

        logger.info(
            f"üì± Created format A/B test {test_id} for formats: {formats}")

        return test_id

    async def get_variant_for_user(self, test_id: str, user_id: str) -> Optional[TestVariant]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if test_id not in self.active_tests:
            return None

        test = self.active_tests[test_id]

        if test.status != TestStatus.RUNNING:
            return None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        assignment_key = f"{test_id}_{user_id}"
        if assignment_key in self.test_assignments:
            variant_id = self.test_assignments[assignment_key]
            return next((v for v in test.variants if v.variant_id == variant_id), None)

        # –ù–∞–∑–Ω–∞—á–∞–µ–º –Ω–æ–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Å–æ–≤
        variant = await self._assign_variant(test, user_id)
        if variant:
            self.test_assignments[assignment_key] = variant.variant_id

        return variant

    async def _assign_variant(self, test: ABTest, user_id: str) -> Optional[TestVariant]:
        """–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à user_id –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        import hashlib
        hash_object = hashlib.md5(f"{test.test_id}_{user_id}".encode())
        hash_value = int(hash_object.hexdigest(), 16) % 10000

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –≤–µ—Å–∞–º
        total_weight = sum(v.weight for v in test.variants)
        normalized_hash = hash_value / 10000.0

        cumulative_weight = 0
        for variant in test.variants:
            cumulative_weight += variant.weight / total_weight
            if normalized_hash <= cumulative_weight:
                return variant

        # Fallback –Ω–∞ –ø–µ—Ä–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        return test.variants[0] if test.variants else None

    async def start_test(self, test_id: str) -> bool:
        """–ó–∞–ø—É—Å–∫ A/B —Ç–µ—Å—Ç–∞"""
        if test_id not in self.active_tests:
            return False

        test = self.active_tests[test_id]

        if len(self.active_tests) >= self.max_concurrent_tests:
            logger.warning(
                f"Cannot start test {test_id}: too many concurrent tests")
            return False

        test.status = TestStatus.RUNNING
        test.start_date = datetime.now()

        logger.info(f"üöÄ Started A/B test {test_id}")

        return True

    async def record_impression(self, test_id: str, variant_id: str):
        """–ó–∞–ø–∏—Å—å –ø–æ–∫–∞–∑–∞"""
        if test_id not in self.active_tests:
            return

        test = self.active_tests[test_id]
        variant = next(
            (v for v in test.variants if v.variant_id == variant_id), None)

        if variant:
            variant.impressions += 1
            test.total_impressions += 1

    async def record_view(self, test_id: str, variant_id: str):
        """–ó–∞–ø–∏—Å—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞"""
        if test_id not in self.active_tests:
            return

        test = self.active_tests[test_id]
        variant = next(
            (v for v in test.variants if v.variant_id == variant_id), None)

        if variant:
            variant.views += 1

    async def record_engagement(self, test_id: str, variant_id: str):
        """–ó–∞–ø–∏—Å—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        if test_id not in self.active_tests:
            return

        test = self.active_tests[test_id]
        variant = next(
            (v for v in test.variants if v.variant_id == variant_id), None)

        if variant:
            variant.engagements += 1

    async def record_click(self, test_id: str, variant_id: str):
        """–ó–∞–ø–∏—Å—å –∫–ª–∏–∫–∞"""
        if test_id not in self.active_tests:
            return

        test = self.active_tests[test_id]
        variant = next(
            (v for v in test.variants if v.variant_id == variant_id), None)

        if variant:
            variant.clicks += 1

    async def record_conversion(self, test_id: str, variant_id: str):
        """–ó–∞–ø–∏—Å—å –∫–æ–Ω–≤–µ—Ä—Å–∏–∏"""
        if test_id not in self.active_tests:
            return

        test = self.active_tests[test_id]
        variant = next(
            (v for v in test.variants if v.variant_id == variant_id), None)

        if variant:
            variant.conversions += 1

    async def get_test_results(self, test_id: str) -> Optional[TestResult]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∞"""
        test = self.active_tests.get(
            test_id) or self.completed_tests.get(test_id)
        if not test:
            return None

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        await self._update_calculated_metrics(test)

        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
        winner_variant = await self._find_winner(test)

        if not winner_variant:
            return None

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–∏–µ
        baseline_variant = test.variants[0]  # –ü–µ—Ä–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –∫–∞–∫ baseline
        improvement = await self._calculate_improvement(
            baseline_variant,
            winner_variant,
            test.primary_metric
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
        statistical_significance = await self._check_statistical_significance(
            baseline_variant,
            winner_variant,
            test.primary_metric
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = await self._generate_recommendation(test, winner_variant, improvement)

        return TestResult(
            test_id=test_id,
            winner_variant_id=winner_variant.variant_id,
            confidence_level=winner_variant.confidence_level,
            improvement_percentage=improvement,
            statistical_significance=statistical_significance,
            recommendation=recommendation,
            detailed_metrics=await self._get_detailed_metrics(test),
            generated_at=datetime.now()
        )

    async def _update_calculated_metrics(self, test: ABTest):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—á–µ—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        for variant in test.variants:
            # Engagement Rate
            if variant.views > 0:
                variant.engagement_rate = variant.engagements / variant.views

            # Click Rate
            if variant.views > 0:
                variant.click_rate = variant.clicks / variant.views

            # Conversion Rate
            if variant.clicks > 0:
                variant.conversion_rate = variant.conversions / variant.clicks

    async def _find_winner(self, test: ABTest) -> Optional[TestVariant]:
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞"""
        if not test.variants:
            return None

        # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π
        valid_variants = [
            v for v in test.variants
            if v.views >= self.min_sample_size
        ]

        if not valid_variants:
            return None

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ
        metric_getter = self._get_metric_value

        sorted_variants = sorted(
            valid_variants,
            key=lambda v: metric_getter(v, test.primary_metric),
            reverse=True
        )

        return sorted_variants[0]

    def _get_metric_value(self, variant: TestVariant, metric: MetricType) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏"""
        if metric == MetricType.ENGAGEMENT_RATE:
            return variant.engagement_rate
        elif metric == MetricType.CLICK_RATE:
            return variant.click_rate
        elif metric == MetricType.CONVERSION_RATE:
            return variant.conversion_rate
        elif metric == MetricType.VIEWS:
            return float(variant.views)
        elif metric == MetricType.COMMENTS:
            return float(variant.engagements)  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ
        else:
            return 0.0

    async def _calculate_improvement(
        self,
        baseline: TestVariant,
        winner: TestVariant,
        metric: MetricType
    ) -> float:
        """–†–∞—Å—á–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö"""
        baseline_value = self._get_metric_value(baseline, metric)
        winner_value = self._get_metric_value(winner, metric)

        if baseline_value == 0:
            return 0.0

        improvement = ((winner_value - baseline_value) / baseline_value) * 100
        return round(improvement, 2)

    async def _check_statistical_significance(
        self,
        baseline: TestVariant,
        variant: TestVariant,
        metric: MetricType
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ z-—Ç–µ—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–π

        if metric in [MetricType.ENGAGEMENT_RATE, MetricType.CLICK_RATE, MetricType.CONVERSION_RATE]:
            # –î–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            baseline_rate = self._get_metric_value(baseline, metric)
            variant_rate = self._get_metric_value(variant, metric)

            n1 = baseline.views
            n2 = variant.views

            if n1 < 30 or n2 < 30:
                return False

            # z-—Ç–µ—Å—Ç –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            p1 = baseline_rate
            p2 = variant_rate

            pooled_p = ((p1 * n1) + (p2 * n2)) / (n1 + n2)
            se = math.sqrt(pooled_p * (1 - pooled_p) * ((1/n1) + (1/n2)))

            if se == 0:
                return False

            z_score = abs(p2 - p1) / se

            # –î–ª—è 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ z = 1.96
            return z_score > 1.96

        return False

    async def _generate_recommendation(
        self,
        test: ABTest,
        winner: TestVariant,
        improvement: float
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        if improvement > 20:
            return f"–°–∏–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {winner.variant_name}. –£–ª—É—á—à–µ–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {improvement:.1f}%."
        elif improvement > 10:
            return f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å {winner.variant_name}. –£–ª—É—á—à–µ–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {improvement:.1f}%."
        elif improvement > 5:
            return f"–°–ª–∞–±–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {winner.variant_name} –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ ({improvement:.1f}%)."
        elif improvement > 0:
            return f"–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {winner.variant_name} –ª—É—á—à–µ –Ω–∞ {improvement:.1f}%, –Ω–æ —Ä–∞–∑–Ω–∏—Ü–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–∞."
        else:
            return f"–ù–µ—Ç –∑–Ω–∞—á–∏–º–æ–π —Ä–∞–∑–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±–æ–π."

    async def _get_detailed_metrics(self, test: ABTest) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        metrics = {
            "test_info": {
                "test_id": test.test_id,
                "test_name": test.test_name,
                "test_type": test.test_type.value,
                "status": test.status.value,
                "duration_days": (datetime.now() - test.start_date).days
            },
            "variants": []
        }

        for variant in test.variants:
            variant_metrics = {
                "variant_id": variant.variant_id,
                "variant_name": variant.variant_name,
                "impressions": variant.impressions,
                "views": variant.views,
                "engagements": variant.engagements,
                "clicks": variant.clicks,
                "conversions": variant.conversions,
                "engagement_rate": round(variant.engagement_rate * 100, 2),
                "click_rate": round(variant.click_rate * 100, 2),
                "conversion_rate": round(variant.conversion_rate * 100, 2)
            }
            metrics["variants"].append(variant_metrics)

        return metrics

    async def stop_test(self, test_id: str, reason: str = "Manual stop") -> bool:
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ A/B —Ç–µ—Å—Ç–∞"""
        if test_id not in self.active_tests:
            return False

        test = self.active_tests[test_id]
        test.status = TestStatus.COMPLETED
        test.end_date = datetime.now()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
        winner = await self._find_winner(test)
        if winner:
            test.winner_variant_id = winner.variant_id

        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        self.completed_tests[test_id] = test
        del self.active_tests[test_id]

        logger.info(f"üèÅ Stopped A/B test {test_id}: {reason}")

        return True

    async def _monitor_active_tests(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        while self.is_running:
            try:
                current_time = datetime.now()

                tests_to_stop = []

                for test_id, test in self.active_tests.items():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è
                    if test.end_date and current_time >= test.end_date:
                        tests_to_stop.append((test_id, "Time expired"))
                        continue

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
                    if test.total_impressions >= test.min_sample_size * len(test.variants):
                        results = await self.get_test_results(test_id)
                        if results and results.statistical_significance and results.confidence_level >= self.min_confidence_level:
                            tests_to_stop.append(
                                (test_id, "Statistical significance reached"))

                # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç—ã
                for test_id, reason in tests_to_stop:
                    await self.stop_test(test_id, reason)

                await asyncio.sleep(3600)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —á–∞—Å

            except Exception as e:
                logger.error(f"Error in test monitoring: {e}")
                await asyncio.sleep(600)

    async def _calculate_test_results(self):
        """–†–∞—Å—á–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤"""
        while self.is_running:
            try:
                for test in self.active_tests.values():
                    await self._update_calculated_metrics(test)

                await asyncio.sleep(900)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç

            except Exception as e:
                logger.error(f"Error calculating test results: {e}")
                await asyncio.sleep(300)

    async def _auto_stop_completed_tests(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        while self.is_running:
            try:
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (—Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π)
                cutoff_time = datetime.now() - timedelta(days=30)
                old_assignments = [
                    key for key, _ in self.test_assignments.items()
                    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
                ]

                # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π

                await asyncio.sleep(86400)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑ –≤ –¥–µ–Ω—å

            except Exception as e:
                logger.error(f"Error in auto cleanup: {e}")
                await asyncio.sleep(3600)

    def get_active_tests(self) -> Dict[str, ABTest]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        return self.active_tests.copy()

    def get_completed_tests(self) -> Dict[str, ABTest]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        return self.completed_tests.copy()

    async def get_test_summary(self, days_back: int = 30) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ —Ç–µ—Å—Ç–∞–º"""
        cutoff_time = datetime.now() - timedelta(days=days_back)

        recent_tests = []
        for test in list(self.active_tests.values()) + list(self.completed_tests.values()):
            if test.start_date >= cutoff_time:
                recent_tests.append(test)

        total_tests = len(recent_tests)
        completed_tests = len(
            [t for t in recent_tests if t.status == TestStatus.COMPLETED])
        successful_tests = len(
            [t for t in recent_tests if t.winner_variant_id is not None])

        avg_improvement = 0
        if successful_tests > 0:
            improvements = []
            for test in recent_tests:
                if test.winner_variant_id and len(test.variants) >= 2:
                    winner = next(
                        (v for v in test.variants if v.variant_id == test.winner_variant_id), None)
                    baseline = test.variants[0]
                    if winner and baseline:
                        improvement = await self._calculate_improvement(baseline, winner, test.primary_metric)
                        improvements.append(improvement)

            if improvements:
                avg_improvement = sum(improvements) / len(improvements)

        return {
            "period_days": days_back,
            "total_tests": total_tests,
            "active_tests": len(self.active_tests),
            "completed_tests": completed_tests,
            "successful_tests": successful_tests,
            "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
            "avg_improvement_percent": round(avg_improvement, 2),
            "test_types": {
                test_type.value: len(
                    [t for t in recent_tests if t.test_type == test_type])
                for test_type in VariantType
            }
        }
